{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T06:27:54.726032Z",
     "start_time": "2024-12-25T06:27:54.679024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 下载数据集\n",
    "trainset = torchvision.datasets.FashionMNIST('./data', download=True, train=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST('./data', download=True, train=False, transform=transform)\n",
    "\n",
    "# 数据加载器\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n"
   ],
   "id": "efca786e72efdcce",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-25T06:27:55.143020Z",
     "start_time": "2024-12-25T06:27:55.135396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T06:27:55.758214Z",
     "start_time": "2024-12-25T06:27:55.754124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
   ],
   "id": "ca002049570dbf15",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T06:27:56.421089Z",
     "start_time": "2024-12-25T06:27:56.416003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/fashion_mnist_experiment_1')\n"
   ],
   "id": "42a3255bfa7b71e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T06:30:41.913290Z",
     "start_time": "2024-12-25T06:28:31.306051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 记录训练过程\n",
    "num_epochs = 3\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # 训练阶段\n",
    "    net.train()\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播 + 后向传播 + 优化\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 统计数据\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # 每100步记录一次损失和准确率\n",
    "        if i % 100 == 99:\n",
    "            print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}\")\n",
    "            writer.add_scalar('training_loss', running_loss / 100, epoch * len(trainloader) + i)\n",
    "            writer.add_scalar('training_accuracy', 100 * correct / total, epoch * len(trainloader) + i)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    # 记录训练损失和准确率\n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    writer.add_scalar('epoch_loss', epoch_loss, epoch)\n",
    "    writer.add_scalar('epoch_accuracy', epoch_accuracy, epoch)\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%\")\n",
    "\n",
    "    # 记录模型的权重和梯度分布\n",
    "    writer.add_histogram('conv1_weights', net.conv1.weight, epoch)\n",
    "    writer.add_histogram('conv1_gradients', net.conv1.weight.grad, epoch)\n",
    "\n",
    "    # 记录模型计算图（第一次进行前向传播时）\n",
    "    if epoch == 0:\n",
    "        writer.add_graph(net, inputs)\n",
    "\n",
    "    # 记录部分训练图像\n",
    "    if epoch == 0:  # 仅在第一个 epoch 时记录\n",
    "        img_grid = torchvision.utils.make_grid(inputs)\n",
    "        writer.add_image('training_images', img_grid)\n"
   ],
   "id": "73063dd3b7eb99db",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.298\n",
      "[1,   200] loss: 2.292\n",
      "[1,   300] loss: 2.277\n",
      "[1,   400] loss: 2.250\n",
      "[1,   500] loss: 2.123\n",
      "[1,   600] loss: 1.703\n",
      "[1,   700] loss: 1.342\n",
      "[1,   800] loss: 1.227\n",
      "[1,   900] loss: 1.114\n",
      "[1,  1000] loss: 1.130\n",
      "[1,  1100] loss: 1.037\n",
      "[1,  1200] loss: 0.913\n",
      "[1,  1300] loss: 0.893\n",
      "[1,  1400] loss: 0.883\n",
      "[1,  1500] loss: 0.859\n",
      "[1,  1600] loss: 0.917\n",
      "[1,  1700] loss: 0.817\n",
      "[1,  1800] loss: 0.822\n",
      "[1,  1900] loss: 0.790\n",
      "[1,  2000] loss: 0.771\n",
      "[1,  2100] loss: 0.738\n",
      "[1,  2200] loss: 0.812\n",
      "[1,  2300] loss: 0.678\n",
      "[1,  2400] loss: 0.828\n",
      "[1,  2500] loss: 0.689\n",
      "[1,  2600] loss: 0.758\n",
      "[1,  2700] loss: 0.697\n",
      "[1,  2800] loss: 0.676\n",
      "[1,  2900] loss: 0.670\n",
      "[1,  3000] loss: 0.692\n",
      "[1,  3100] loss: 0.701\n",
      "[1,  3200] loss: 0.691\n",
      "[1,  3300] loss: 0.650\n",
      "[1,  3400] loss: 0.705\n",
      "[1,  3500] loss: 0.625\n",
      "[1,  3600] loss: 0.594\n",
      "[1,  3700] loss: 0.609\n",
      "[1,  3800] loss: 0.607\n",
      "[1,  3900] loss: 0.710\n",
      "[1,  4000] loss: 0.641\n",
      "[1,  4100] loss: 0.657\n",
      "[1,  4200] loss: 0.648\n",
      "[1,  4300] loss: 0.555\n",
      "[1,  4400] loss: 0.686\n",
      "[1,  4500] loss: 0.674\n",
      "[1,  4600] loss: 0.565\n",
      "[1,  4700] loss: 0.612\n",
      "[1,  4800] loss: 0.557\n",
      "[1,  4900] loss: 0.588\n",
      "[1,  5000] loss: 0.564\n",
      "[1,  5100] loss: 0.576\n",
      "[1,  5200] loss: 0.567\n",
      "[1,  5300] loss: 0.530\n",
      "[1,  5400] loss: 0.645\n",
      "[1,  5500] loss: 0.625\n",
      "[1,  5600] loss: 0.580\n",
      "[1,  5700] loss: 0.518\n",
      "[1,  5800] loss: 0.568\n",
      "[1,  5900] loss: 0.632\n",
      "[1,  6000] loss: 0.541\n",
      "[1,  6100] loss: 0.429\n",
      "[1,  6200] loss: 0.487\n",
      "[1,  6300] loss: 0.595\n",
      "[1,  6400] loss: 0.546\n",
      "[1,  6500] loss: 0.514\n",
      "[1,  6600] loss: 0.535\n",
      "[1,  6700] loss: 0.500\n",
      "[1,  6800] loss: 0.529\n",
      "[1,  6900] loss: 0.527\n",
      "[1,  7000] loss: 0.592\n",
      "[1,  7100] loss: 0.517\n",
      "[1,  7200] loss: 0.554\n",
      "[1,  7300] loss: 0.490\n",
      "[1,  7400] loss: 0.515\n",
      "[1,  7500] loss: 0.499\n",
      "[1,  7600] loss: 0.497\n",
      "[1,  7700] loss: 0.494\n",
      "[1,  7800] loss: 0.530\n",
      "[1,  7900] loss: 0.466\n",
      "[1,  8000] loss: 0.447\n",
      "[1,  8100] loss: 0.544\n",
      "[1,  8200] loss: 0.544\n",
      "[1,  8300] loss: 0.496\n",
      "[1,  8400] loss: 0.482\n",
      "[1,  8500] loss: 0.466\n",
      "[1,  8600] loss: 0.553\n",
      "[1,  8700] loss: 0.503\n",
      "[1,  8800] loss: 0.490\n",
      "[1,  8900] loss: 0.514\n",
      "[1,  9000] loss: 0.429\n",
      "[1,  9100] loss: 0.420\n",
      "[1,  9200] loss: 0.484\n",
      "[1,  9300] loss: 0.511\n",
      "[1,  9400] loss: 0.488\n",
      "[1,  9500] loss: 0.418\n",
      "[1,  9600] loss: 0.545\n",
      "[1,  9700] loss: 0.419\n",
      "[1,  9800] loss: 0.400\n",
      "[1,  9900] loss: 0.518\n",
      "[1, 10000] loss: 0.448\n",
      "[1, 10100] loss: 0.527\n",
      "[1, 10200] loss: 0.513\n",
      "[1, 10300] loss: 0.393\n",
      "[1, 10400] loss: 0.440\n",
      "[1, 10500] loss: 0.431\n",
      "[1, 10600] loss: 0.543\n",
      "[1, 10700] loss: 0.378\n",
      "[1, 10800] loss: 0.489\n",
      "[1, 10900] loss: 0.440\n",
      "[1, 11000] loss: 0.474\n",
      "[1, 11100] loss: 0.435\n",
      "[1, 11200] loss: 0.423\n",
      "[1, 11300] loss: 0.476\n",
      "[1, 11400] loss: 0.404\n",
      "[1, 11500] loss: 0.404\n",
      "[1, 11600] loss: 0.424\n",
      "[1, 11700] loss: 0.411\n",
      "[1, 11800] loss: 0.606\n",
      "[1, 11900] loss: 0.411\n",
      "[1, 12000] loss: 0.388\n",
      "[1, 12100] loss: 0.474\n",
      "[1, 12200] loss: 0.464\n",
      "[1, 12300] loss: 0.506\n",
      "[1, 12400] loss: 0.453\n",
      "[1, 12500] loss: 0.482\n",
      "[1, 12600] loss: 0.414\n",
      "[1, 12700] loss: 0.450\n",
      "[1, 12800] loss: 0.412\n",
      "[1, 12900] loss: 0.400\n",
      "[1, 13000] loss: 0.449\n",
      "[1, 13100] loss: 0.442\n",
      "[1, 13200] loss: 0.390\n",
      "[1, 13300] loss: 0.355\n",
      "[1, 13400] loss: 0.464\n",
      "[1, 13500] loss: 0.494\n",
      "[1, 13600] loss: 0.359\n",
      "[1, 13700] loss: 0.452\n",
      "[1, 13800] loss: 0.434\n",
      "[1, 13900] loss: 0.426\n",
      "[1, 14000] loss: 0.427\n",
      "[1, 14100] loss: 0.384\n",
      "[1, 14200] loss: 0.501\n",
      "[1, 14300] loss: 0.386\n",
      "[1, 14400] loss: 0.387\n",
      "[1, 14500] loss: 0.458\n",
      "[1, 14600] loss: 0.409\n",
      "[1, 14700] loss: 0.407\n",
      "[1, 14800] loss: 0.345\n",
      "[1, 14900] loss: 0.354\n",
      "[1, 15000] loss: 0.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:48<01:37, 48.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3] - Loss: 0.0000, Accuracy: 76.69%\n",
      "[2,   100] loss: 0.459\n",
      "[2,   200] loss: 0.387\n",
      "[2,   300] loss: 0.485\n",
      "[2,   400] loss: 0.386\n",
      "[2,   500] loss: 0.333\n",
      "[2,   600] loss: 0.470\n",
      "[2,   700] loss: 0.424\n",
      "[2,   800] loss: 0.447\n",
      "[2,   900] loss: 0.431\n",
      "[2,  1000] loss: 0.378\n",
      "[2,  1100] loss: 0.394\n",
      "[2,  1200] loss: 0.394\n",
      "[2,  1300] loss: 0.442\n",
      "[2,  1400] loss: 0.418\n",
      "[2,  1500] loss: 0.400\n",
      "[2,  1600] loss: 0.389\n",
      "[2,  1700] loss: 0.347\n",
      "[2,  1800] loss: 0.403\n",
      "[2,  1900] loss: 0.412\n",
      "[2,  2000] loss: 0.421\n",
      "[2,  2100] loss: 0.378\n",
      "[2,  2200] loss: 0.349\n",
      "[2,  2300] loss: 0.422\n",
      "[2,  2400] loss: 0.333\n",
      "[2,  2500] loss: 0.371\n",
      "[2,  2600] loss: 0.419\n",
      "[2,  2700] loss: 0.381\n",
      "[2,  2800] loss: 0.398\n",
      "[2,  2900] loss: 0.411\n",
      "[2,  3000] loss: 0.402\n",
      "[2,  3100] loss: 0.372\n",
      "[2,  3200] loss: 0.381\n",
      "[2,  3300] loss: 0.374\n",
      "[2,  3400] loss: 0.476\n",
      "[2,  3500] loss: 0.419\n",
      "[2,  3600] loss: 0.383\n",
      "[2,  3700] loss: 0.331\n",
      "[2,  3800] loss: 0.421\n",
      "[2,  3900] loss: 0.363\n",
      "[2,  4000] loss: 0.464\n",
      "[2,  4100] loss: 0.354\n",
      "[2,  4200] loss: 0.366\n",
      "[2,  4300] loss: 0.256\n",
      "[2,  4400] loss: 0.403\n",
      "[2,  4500] loss: 0.379\n",
      "[2,  4600] loss: 0.373\n",
      "[2,  4700] loss: 0.364\n",
      "[2,  4800] loss: 0.378\n",
      "[2,  4900] loss: 0.446\n",
      "[2,  5000] loss: 0.332\n",
      "[2,  5100] loss: 0.393\n",
      "[2,  5200] loss: 0.353\n",
      "[2,  5300] loss: 0.318\n",
      "[2,  5400] loss: 0.341\n",
      "[2,  5500] loss: 0.405\n",
      "[2,  5600] loss: 0.321\n",
      "[2,  5700] loss: 0.324\n",
      "[2,  5800] loss: 0.346\n",
      "[2,  5900] loss: 0.393\n",
      "[2,  6000] loss: 0.395\n",
      "[2,  6100] loss: 0.372\n",
      "[2,  6200] loss: 0.393\n",
      "[2,  6300] loss: 0.368\n",
      "[2,  6400] loss: 0.370\n",
      "[2,  6500] loss: 0.452\n",
      "[2,  6600] loss: 0.352\n",
      "[2,  6700] loss: 0.461\n",
      "[2,  6800] loss: 0.350\n",
      "[2,  6900] loss: 0.361\n",
      "[2,  7000] loss: 0.427\n",
      "[2,  7100] loss: 0.365\n",
      "[2,  7200] loss: 0.282\n",
      "[2,  7300] loss: 0.439\n",
      "[2,  7400] loss: 0.360\n",
      "[2,  7500] loss: 0.339\n",
      "[2,  7600] loss: 0.315\n",
      "[2,  7700] loss: 0.306\n",
      "[2,  7800] loss: 0.302\n",
      "[2,  7900] loss: 0.467\n",
      "[2,  8000] loss: 0.323\n",
      "[2,  8100] loss: 0.426\n",
      "[2,  8200] loss: 0.412\n",
      "[2,  8300] loss: 0.420\n",
      "[2,  8400] loss: 0.381\n",
      "[2,  8500] loss: 0.339\n",
      "[2,  8600] loss: 0.325\n",
      "[2,  8700] loss: 0.362\n",
      "[2,  8800] loss: 0.324\n",
      "[2,  8900] loss: 0.408\n",
      "[2,  9000] loss: 0.338\n",
      "[2,  9100] loss: 0.338\n",
      "[2,  9200] loss: 0.326\n",
      "[2,  9300] loss: 0.364\n",
      "[2,  9400] loss: 0.377\n",
      "[2,  9500] loss: 0.347\n",
      "[2,  9600] loss: 0.414\n",
      "[2,  9700] loss: 0.394\n",
      "[2,  9800] loss: 0.388\n",
      "[2,  9900] loss: 0.324\n",
      "[2, 10000] loss: 0.359\n",
      "[2, 10100] loss: 0.454\n",
      "[2, 10200] loss: 0.274\n",
      "[2, 10300] loss: 0.382\n",
      "[2, 10400] loss: 0.388\n",
      "[2, 10500] loss: 0.457\n",
      "[2, 10600] loss: 0.304\n",
      "[2, 10700] loss: 0.322\n",
      "[2, 10800] loss: 0.346\n",
      "[2, 10900] loss: 0.399\n",
      "[2, 11000] loss: 0.408\n",
      "[2, 11100] loss: 0.343\n",
      "[2, 11200] loss: 0.324\n",
      "[2, 11300] loss: 0.381\n",
      "[2, 11400] loss: 0.314\n",
      "[2, 11500] loss: 0.350\n",
      "[2, 11600] loss: 0.397\n",
      "[2, 11700] loss: 0.319\n",
      "[2, 11800] loss: 0.325\n",
      "[2, 11900] loss: 0.336\n",
      "[2, 12000] loss: 0.360\n",
      "[2, 12100] loss: 0.408\n",
      "[2, 12200] loss: 0.405\n",
      "[2, 12300] loss: 0.438\n",
      "[2, 12400] loss: 0.337\n",
      "[2, 12500] loss: 0.313\n",
      "[2, 12600] loss: 0.347\n",
      "[2, 12700] loss: 0.308\n",
      "[2, 12800] loss: 0.291\n",
      "[2, 12900] loss: 0.323\n",
      "[2, 13000] loss: 0.318\n",
      "[2, 13100] loss: 0.367\n",
      "[2, 13200] loss: 0.356\n",
      "[2, 13300] loss: 0.367\n",
      "[2, 13400] loss: 0.368\n",
      "[2, 13500] loss: 0.359\n",
      "[2, 13600] loss: 0.341\n",
      "[2, 13700] loss: 0.322\n",
      "[2, 13800] loss: 0.335\n",
      "[2, 13900] loss: 0.360\n",
      "[2, 14000] loss: 0.364\n",
      "[2, 14100] loss: 0.343\n",
      "[2, 14200] loss: 0.313\n",
      "[2, 14300] loss: 0.314\n",
      "[2, 14400] loss: 0.373\n",
      "[2, 14500] loss: 0.332\n",
      "[2, 14600] loss: 0.309\n",
      "[2, 14700] loss: 0.362\n",
      "[2, 14800] loss: 0.341\n",
      "[2, 14900] loss: 0.339\n",
      "[2, 15000] loss: 0.291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [01:24<00:41, 41.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/3] - Loss: 0.0000, Accuracy: 86.51%\n",
      "[3,   100] loss: 0.367\n",
      "[3,   200] loss: 0.400\n",
      "[3,   300] loss: 0.283\n",
      "[3,   400] loss: 0.282\n",
      "[3,   500] loss: 0.315\n",
      "[3,   600] loss: 0.355\n",
      "[3,   700] loss: 0.341\n",
      "[3,   800] loss: 0.411\n",
      "[3,   900] loss: 0.403\n",
      "[3,  1000] loss: 0.304\n",
      "[3,  1100] loss: 0.297\n",
      "[3,  1200] loss: 0.333\n",
      "[3,  1300] loss: 0.301\n",
      "[3,  1400] loss: 0.300\n",
      "[3,  1500] loss: 0.331\n",
      "[3,  1600] loss: 0.312\n",
      "[3,  1700] loss: 0.283\n",
      "[3,  1800] loss: 0.299\n",
      "[3,  1900] loss: 0.299\n",
      "[3,  2000] loss: 0.282\n",
      "[3,  2100] loss: 0.357\n",
      "[3,  2200] loss: 0.292\n",
      "[3,  2300] loss: 0.376\n",
      "[3,  2400] loss: 0.334\n",
      "[3,  2500] loss: 0.299\n",
      "[3,  2600] loss: 0.340\n",
      "[3,  2700] loss: 0.320\n",
      "[3,  2800] loss: 0.310\n",
      "[3,  2900] loss: 0.262\n",
      "[3,  3000] loss: 0.368\n",
      "[3,  3100] loss: 0.288\n",
      "[3,  3200] loss: 0.390\n",
      "[3,  3300] loss: 0.301\n",
      "[3,  3400] loss: 0.327\n",
      "[3,  3500] loss: 0.312\n",
      "[3,  3600] loss: 0.268\n",
      "[3,  3700] loss: 0.315\n",
      "[3,  3800] loss: 0.331\n",
      "[3,  3900] loss: 0.273\n",
      "[3,  4000] loss: 0.262\n",
      "[3,  4100] loss: 0.345\n",
      "[3,  4200] loss: 0.365\n",
      "[3,  4300] loss: 0.370\n",
      "[3,  4400] loss: 0.383\n",
      "[3,  4500] loss: 0.347\n",
      "[3,  4600] loss: 0.300\n",
      "[3,  4700] loss: 0.336\n",
      "[3,  4800] loss: 0.277\n",
      "[3,  4900] loss: 0.294\n",
      "[3,  5000] loss: 0.362\n",
      "[3,  5100] loss: 0.361\n",
      "[3,  5200] loss: 0.354\n",
      "[3,  5300] loss: 0.321\n",
      "[3,  5400] loss: 0.315\n",
      "[3,  5500] loss: 0.385\n",
      "[3,  5600] loss: 0.318\n",
      "[3,  5700] loss: 0.348\n",
      "[3,  5800] loss: 0.348\n",
      "[3,  5900] loss: 0.347\n",
      "[3,  6000] loss: 0.326\n",
      "[3,  6100] loss: 0.351\n",
      "[3,  6200] loss: 0.302\n",
      "[3,  6300] loss: 0.368\n",
      "[3,  6400] loss: 0.246\n",
      "[3,  6500] loss: 0.330\n",
      "[3,  6600] loss: 0.397\n",
      "[3,  6700] loss: 0.250\n",
      "[3,  6800] loss: 0.300\n",
      "[3,  6900] loss: 0.334\n",
      "[3,  7000] loss: 0.304\n",
      "[3,  7100] loss: 0.384\n",
      "[3,  7200] loss: 0.258\n",
      "[3,  7300] loss: 0.263\n",
      "[3,  7400] loss: 0.323\n",
      "[3,  7500] loss: 0.371\n",
      "[3,  7600] loss: 0.343\n",
      "[3,  7700] loss: 0.324\n",
      "[3,  7800] loss: 0.309\n",
      "[3,  7900] loss: 0.406\n",
      "[3,  8000] loss: 0.367\n",
      "[3,  8100] loss: 0.368\n",
      "[3,  8200] loss: 0.314\n",
      "[3,  8300] loss: 0.328\n",
      "[3,  8400] loss: 0.323\n",
      "[3,  8500] loss: 0.350\n",
      "[3,  8600] loss: 0.309\n",
      "[3,  8700] loss: 0.286\n",
      "[3,  8800] loss: 0.338\n",
      "[3,  8900] loss: 0.367\n",
      "[3,  9000] loss: 0.315\n",
      "[3,  9100] loss: 0.313\n",
      "[3,  9200] loss: 0.333\n",
      "[3,  9300] loss: 0.397\n",
      "[3,  9400] loss: 0.356\n",
      "[3,  9500] loss: 0.318\n",
      "[3,  9600] loss: 0.302\n",
      "[3,  9700] loss: 0.333\n",
      "[3,  9800] loss: 0.309\n",
      "[3,  9900] loss: 0.301\n",
      "[3, 10000] loss: 0.361\n",
      "[3, 10100] loss: 0.363\n",
      "[3, 10200] loss: 0.341\n",
      "[3, 10300] loss: 0.310\n",
      "[3, 10400] loss: 0.246\n",
      "[3, 10500] loss: 0.306\n",
      "[3, 10600] loss: 0.304\n",
      "[3, 10700] loss: 0.313\n",
      "[3, 10800] loss: 0.286\n",
      "[3, 10900] loss: 0.361\n",
      "[3, 11000] loss: 0.308\n",
      "[3, 11100] loss: 0.293\n",
      "[3, 11200] loss: 0.364\n",
      "[3, 11300] loss: 0.325\n",
      "[3, 11400] loss: 0.254\n",
      "[3, 11500] loss: 0.316\n",
      "[3, 11600] loss: 0.303\n",
      "[3, 11700] loss: 0.284\n",
      "[3, 11800] loss: 0.402\n",
      "[3, 11900] loss: 0.303\n",
      "[3, 12000] loss: 0.299\n",
      "[3, 12100] loss: 0.278\n",
      "[3, 12200] loss: 0.290\n",
      "[3, 12300] loss: 0.347\n",
      "[3, 12400] loss: 0.295\n",
      "[3, 12500] loss: 0.339\n",
      "[3, 12600] loss: 0.304\n",
      "[3, 12700] loss: 0.298\n",
      "[3, 12800] loss: 0.346\n",
      "[3, 12900] loss: 0.351\n",
      "[3, 13000] loss: 0.349\n",
      "[3, 13100] loss: 0.289\n",
      "[3, 13200] loss: 0.434\n",
      "[3, 13300] loss: 0.372\n",
      "[3, 13400] loss: 0.306\n",
      "[3, 13500] loss: 0.284\n",
      "[3, 13600] loss: 0.328\n",
      "[3, 13700] loss: 0.315\n",
      "[3, 13800] loss: 0.336\n",
      "[3, 13900] loss: 0.296\n",
      "[3, 14000] loss: 0.273\n",
      "[3, 14100] loss: 0.299\n",
      "[3, 14200] loss: 0.301\n",
      "[3, 14300] loss: 0.369\n",
      "[3, 14400] loss: 0.343\n",
      "[3, 14500] loss: 0.270\n",
      "[3, 14600] loss: 0.277\n",
      "[3, 14700] loss: 0.339\n",
      "[3, 14800] loss: 0.294\n",
      "[3, 14900] loss: 0.284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:06<00:00, 41.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 15000] loss: 0.326\n",
      "Epoch [3/3] - Loss: 0.0000, Accuracy: 88.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:06<00:00, 42.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 86.49%\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-25T06:30:56.187399Z",
     "start_time": "2024-12-25T06:30:52.484209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 测试阶段\n",
    "correct = 0\n",
    "total = 0\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
    "writer.add_scalar('test_accuracy', test_accuracy)\n",
    "\n",
    "# 关闭 TensorBoard 记录器\n",
    "writer.close()"
   ],
   "id": "858552dc490fdc64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 86.49%\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "cf651b8813a4adf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
