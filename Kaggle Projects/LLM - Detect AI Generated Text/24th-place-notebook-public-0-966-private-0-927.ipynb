{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f752193e",
   "metadata": {
    "papermill": {
     "duration": 0.01574,
     "end_time": "2024-01-18T07:51:06.738283",
     "exception": false,
     "start_time": "2024-01-18T07:51:06.722543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LM Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2040aa65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:51:06.769672Z",
     "iopub.status.busy": "2024-01-18T07:51:06.769395Z",
     "iopub.status.idle": "2024-01-18T07:51:07.448278Z",
     "shell.execute_reply": "2024-01-18T07:51:07.447542Z"
    },
    "papermill": {
     "duration": 0.696959,
     "end_time": "2024-01-18T07:51:07.450569",
     "exception": false,
     "start_time": "2024-01-18T07:51:06.753610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5044f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:51:07.482443Z",
     "iopub.status.busy": "2024-01-18T07:51:07.482056Z",
     "iopub.status.idle": "2024-01-18T07:51:55.065073Z",
     "shell.execute_reply": "2024-01-18T07:51:55.063926Z"
    },
    "papermill": {
     "duration": 47.601333,
     "end_time": "2024-01-18T07:51:55.067487",
     "exception": false,
     "start_time": "2024-01-18T07:51:07.466154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/ex-library\r\n",
      "Processing /kaggle/input/ex-library/hydra_core-1.3.2-py3-none-any.whl\r\n",
      "Processing /kaggle/input/ex-library/omegaconf-2.3.0-py3-none-any.whl (from hydra-core)\r\n",
      "Processing /kaggle/input/ex-library/antlr4-python3-runtime-4.9.3.tar.gz (from hydra-core)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from hydra-core) (21.3)\r\n",
      "Requirement already satisfied: PyYAML>=5.1.0 in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0.1)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->hydra-core) (3.0.9)\r\n",
      "Building wheels for collected packages: antlr4-python3-runtime\r\n",
      "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=a4b50637d75418096e2b3e744843e720abd478f9c32b10ac335e1f9532fa3d15\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bf/5c/34/cdd531f2be0298fb3c66c4db6dff71ec7385fc1fd2d5d60436\r\n",
      "Successfully built antlr4-python3-runtime\r\n",
      "Installing collected packages: antlr4-python3-runtime, omegaconf, hydra-core\r\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 omegaconf-2.3.0\r\n",
      "Processing /kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\r\n",
      "Installing collected packages: pyspellchecker\r\n",
      "Successfully installed pyspellchecker-0.7.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install hydra-core --no-index --find-links=/kaggle/input/ex-library\n",
    "!pip install \"/kaggle/input/pyspellchecker/pyspellchecker-0.7.2-py3-none-any.whl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647ab6ce",
   "metadata": {
    "papermill": {
     "duration": 0.016897,
     "end_time": "2024-01-18T07:51:55.101257",
     "exception": false,
     "start_time": "2024-01-18T07:51:55.084360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LM 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f744668a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:51:55.135143Z",
     "iopub.status.busy": "2024-01-18T07:51:55.134567Z",
     "iopub.status.idle": "2024-01-18T07:51:55.147239Z",
     "shell.execute_reply": "2024-01-18T07:51:55.146249Z"
    },
    "papermill": {
     "duration": 0.031747,
     "end_time": "2024-01-18T07:51:55.149185",
     "exception": false,
     "start_time": "2024-01-18T07:51:55.117438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dai-code/run\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/input/dai-code/run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c83e3c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:51:55.182615Z",
     "iopub.status.busy": "2024-01-18T07:51:55.182352Z",
     "iopub.status.idle": "2024-01-18T07:51:56.143170Z",
     "shell.execute_reply": "2024-01-18T07:51:56.142251Z"
    },
    "papermill": {
     "duration": 0.980069,
     "end_time": "2024-01-18T07:51:56.145379",
     "exception": false,
     "start_time": "2024-01-18T07:51:55.165310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mconf\u001b[0m/  inference.py  preprocess.py  \u001b[01;34msrc\u001b[0m/  train.py  \u001b[01;34mwandb\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4269278",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:51:56.179693Z",
     "iopub.status.busy": "2024-01-18T07:51:56.179372Z",
     "iopub.status.idle": "2024-01-18T07:51:56.183930Z",
     "shell.execute_reply": "2024-01-18T07:51:56.183120Z"
    },
    "papermill": {
     "duration": 0.023805,
     "end_time": "2024-01-18T07:51:56.185738",
     "exception": false,
     "start_time": "2024-01-18T07:51:56.161933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Basic Config ###\n",
    "EXP_NAME = 'exp039'\n",
    "MAX_LENGTH = 512 # inference max length\n",
    "# model_folder_name='debertav3xsmall'\n",
    "model_folder_name='huggingfacedebertav3variants/deberta-v3-large'\n",
    "# model_folder_name='huggingfacedebertav3variants/deberta-v3-base'\n",
    "\n",
    "\n",
    "### Post-process Config ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651f9da6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:51:56.223574Z",
     "iopub.status.busy": "2024-01-18T07:51:56.223288Z",
     "iopub.status.idle": "2024-01-18T07:52:09.933357Z",
     "shell.execute_reply": "2024-01-18T07:52:09.932404Z"
    },
    "papermill": {
     "duration": 13.733972,
     "end_time": "2024-01-18T07:52:09.935908",
     "exception": false,
     "start_time": "2024-01-18T07:51:56.201936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      ">>> Run Preprocess\r\n",
      ">>> MAKE LM_test_preprocessed.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Preprocess\n",
    "!python -m preprocess\\\n",
    "    dir=kaggle\\\n",
    "    phase=inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09bbf25d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:52:09.972181Z",
     "iopub.status.busy": "2024-01-18T07:52:09.971820Z",
     "iopub.status.idle": "2024-01-18T07:52:43.083800Z",
     "shell.execute_reply": "2024-01-18T07:52:43.082777Z"
    },
    "papermill": {
     "duration": 33.13246,
     "end_time": "2024-01-18T07:52:43.086231",
     "exception": false,
     "start_time": "2024-01-18T07:52:09.953771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "Run Inference\r\n",
      ">>> Load Test DataFrame & Make test_ds: COMPLETE\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\r\n",
      "  warnings.warn(\r\n",
      ">>> Define Tokenizer: COMPLETE\r\n",
      "[2024-01-18 07:52:27,802][datasets.fingerprint][WARNING] - Parameter 'function'=<function main.<locals>.tokenize_function at 0x7e1cc2dcb0a0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 22.67ba/s]\r\n",
      ">>> APPLY Tokenizer: COMPLETE\r\n",
      ">>> Find Best Model : /kaggle/input/dai-model/exp039/best_model/checkpoint-26415\r\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\r\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 2641.25it/s]\r\n",
      ">>> Predict: COMPLETE\r\n",
      ">>> No Post Process\r\n",
      ">>> Let's Make submission.csv\r\n",
      ">>> Inference COMPLETE\r\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "!python -m inference\\\n",
    "    dir=kaggle\\\n",
    "    exp_name=$EXP_NAME\\\n",
    "    max_length=$MAX_LENGTH\\\n",
    "    model_folder_name=$model_folder_name\\\n",
    "    post_process=False\\\n",
    "    best_model_dir=best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "825e3cf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:52:43.166951Z",
     "iopub.status.busy": "2024-01-18T07:52:43.166573Z",
     "iopub.status.idle": "2024-01-18T07:52:43.189674Z",
     "shell.execute_reply": "2024-01-18T07:52:43.188807Z"
    },
    "papermill": {
     "duration": 0.087394,
     "end_time": "2024-01-18T07:52:43.191577",
     "exception": false,
     "start_time": "2024-01-18T07:52:43.104183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   0.000047\n",
       "1  1111bbbb   0.000062\n",
       "2  2222cccc   0.000021"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/kaggle/working/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e4bdea4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:52:43.227357Z",
     "iopub.status.busy": "2024-01-18T07:52:43.227096Z",
     "iopub.status.idle": "2024-01-18T07:52:43.231251Z",
     "shell.execute_reply": "2024-01-18T07:52:43.230379Z"
    },
    "papermill": {
     "duration": 0.024217,
     "end_time": "2024-01-18T07:52:43.233133",
     "exception": false,
     "start_time": "2024-01-18T07:52:43.208916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.rename('/kaggle/working/submission.csv', '/kaggle/working/submission_LM1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45b49408",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:52:43.269431Z",
     "iopub.status.busy": "2024-01-18T07:52:43.268704Z",
     "iopub.status.idle": "2024-01-18T07:52:43.278536Z",
     "shell.execute_reply": "2024-01-18T07:52:43.277710Z"
    },
    "papermill": {
     "duration": 0.029963,
     "end_time": "2024-01-18T07:52:43.280624",
     "exception": false,
     "start_time": "2024-01-18T07:52:43.250661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.000062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   0.000047\n",
       "1  1111bbbb   0.000062\n",
       "2  2222cccc   0.000021"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/kaggle/working/submission_LM1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663b3be4",
   "metadata": {
    "papermill": {
     "duration": 0.017538,
     "end_time": "2024-01-18T07:52:43.317526",
     "exception": false,
     "start_time": "2024-01-18T07:52:43.299988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32453c31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:52:43.354381Z",
     "iopub.status.busy": "2024-01-18T07:52:43.354109Z",
     "iopub.status.idle": "2024-01-18T07:52:43.359517Z",
     "shell.execute_reply": "2024-01-18T07:52:43.358642Z"
    },
    "papermill": {
     "duration": 0.026007,
     "end_time": "2024-01-18T07:52:43.361448",
     "exception": false,
     "start_time": "2024-01-18T07:52:43.335441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dai-code/run\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/input/dai-code/run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ba3d688",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:52:43.400605Z",
     "iopub.status.busy": "2024-01-18T07:52:43.400080Z",
     "iopub.status.idle": "2024-01-18T07:52:44.370542Z",
     "shell.execute_reply": "2024-01-18T07:52:44.369301Z"
    },
    "papermill": {
     "duration": 0.992526,
     "end_time": "2024-01-18T07:52:44.372880",
     "exception": false,
     "start_time": "2024-01-18T07:52:43.380354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mconf\u001b[0m/  inference.py  preprocess.py  \u001b[01;34msrc\u001b[0m/  train.py  \u001b[01;34mwandb\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f32390d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:52:44.410047Z",
     "iopub.status.busy": "2024-01-18T07:52:44.409707Z",
     "iopub.status.idle": "2024-01-18T07:52:44.414353Z",
     "shell.execute_reply": "2024-01-18T07:52:44.413582Z"
    },
    "papermill": {
     "duration": 0.025437,
     "end_time": "2024-01-18T07:52:44.416223",
     "exception": false,
     "start_time": "2024-01-18T07:52:44.390786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Basic Config ###\n",
    "EXP_NAME = 'exp045'\n",
    "MAX_LENGTH = 512 # inference max length\n",
    "# model_folder_name='debertav3xsmall'\n",
    "model_folder_name='huggingfacedebertav3variants/deberta-v3-large'\n",
    "# model_folder_name='huggingfacedebertav3variants/deberta-v3-base'\n",
    "\n",
    "\n",
    "### Post-process Config ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02c931d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:52:44.452515Z",
     "iopub.status.busy": "2024-01-18T07:52:44.452234Z",
     "iopub.status.idle": "2024-01-18T07:52:52.201697Z",
     "shell.execute_reply": "2024-01-18T07:52:52.200682Z"
    },
    "papermill": {
     "duration": 7.770489,
     "end_time": "2024-01-18T07:52:52.204283",
     "exception": false,
     "start_time": "2024-01-18T07:52:44.433794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      ">>> Run Preprocess\r\n",
      ">>> MAKE LM_test_preprocessed.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Preprocess\n",
    "!python -m preprocess\\\n",
    "    dir=kaggle\\\n",
    "    phase=inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bfa350f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:52:52.243666Z",
     "iopub.status.busy": "2024-01-18T07:52:52.243286Z",
     "iopub.status.idle": "2024-01-18T07:53:17.051824Z",
     "shell.execute_reply": "2024-01-18T07:53:17.050566Z"
    },
    "papermill": {
     "duration": 24.830962,
     "end_time": "2024-01-18T07:53:17.054325",
     "exception": false,
     "start_time": "2024-01-18T07:52:52.223363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "Run Inference\r\n",
      ">>> Load Test DataFrame & Make test_ds: COMPLETE\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\r\n",
      "  warnings.warn(\r\n",
      ">>> Define Tokenizer: COMPLETE\r\n",
      "[2024-01-18 07:53:02,879][datasets.fingerprint][WARNING] - Parameter 'function'=<function main.<locals>.tokenize_function at 0x7eefd37d7ac0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 74.15ba/s]\r\n",
      ">>> APPLY Tokenizer: COMPLETE\r\n",
      ">>> Find Best Model : /kaggle/input/dai-model-45/exp045/best_model/checkpoint-26415\r\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\r\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 2312.19it/s]\r\n",
      ">>> Predict: COMPLETE\r\n",
      ">>> No Post Process\r\n",
      ">>> Let's Make submission.csv\r\n",
      ">>> Inference COMPLETE\r\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "!python -m inference\\\n",
    "    dir=kaggle\\\n",
    "    exp_name=$EXP_NAME\\\n",
    "    max_length=$MAX_LENGTH\\\n",
    "    model_folder_name=$model_folder_name\\\n",
    "    post_process=False\\\n",
    "    best_model_dir=best_model\\\n",
    "    dir.model_dir=/kaggle/input/dai-model-45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e9fd667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:53:17.095756Z",
     "iopub.status.busy": "2024-01-18T07:53:17.095418Z",
     "iopub.status.idle": "2024-01-18T07:53:17.108525Z",
     "shell.execute_reply": "2024-01-18T07:53:17.107585Z"
    },
    "papermill": {
     "duration": 0.036399,
     "end_time": "2024-01-18T07:53:17.110728",
     "exception": false,
     "start_time": "2024-01-18T07:53:17.074329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.043820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   0.000367\n",
       "1  1111bbbb   0.043820\n",
       "2  2222cccc   0.000202"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/kaggle/working/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "570da288",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:53:17.150952Z",
     "iopub.status.busy": "2024-01-18T07:53:17.150632Z",
     "iopub.status.idle": "2024-01-18T07:53:17.154752Z",
     "shell.execute_reply": "2024-01-18T07:53:17.154063Z"
    },
    "papermill": {
     "duration": 0.025724,
     "end_time": "2024-01-18T07:53:17.156693",
     "exception": false,
     "start_time": "2024-01-18T07:53:17.130969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.rename('/kaggle/working/submission.csv', '/kaggle/working/submission_LM2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3799dbfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:53:17.194733Z",
     "iopub.status.busy": "2024-01-18T07:53:17.194468Z",
     "iopub.status.idle": "2024-01-18T07:53:17.204406Z",
     "shell.execute_reply": "2024-01-18T07:53:17.203576Z"
    },
    "papermill": {
     "duration": 0.031457,
     "end_time": "2024-01-18T07:53:17.206582",
     "exception": false,
     "start_time": "2024-01-18T07:53:17.175125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.000367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.043820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.000202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   0.000367\n",
       "1  1111bbbb   0.043820\n",
       "2  2222cccc   0.000202"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/kaggle/working/submission_LM2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b818fa6",
   "metadata": {
    "papermill": {
     "duration": 0.019344,
     "end_time": "2024-01-18T07:53:17.245274",
     "exception": false,
     "start_time": "2024-01-18T07:53:17.225930",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LM3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5afaa7d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:53:17.283603Z",
     "iopub.status.busy": "2024-01-18T07:53:17.283342Z",
     "iopub.status.idle": "2024-01-18T07:53:17.288740Z",
     "shell.execute_reply": "2024-01-18T07:53:17.287843Z"
    },
    "papermill": {
     "duration": 0.026663,
     "end_time": "2024-01-18T07:53:17.290624",
     "exception": false,
     "start_time": "2024-01-18T07:53:17.263961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dai-code/run\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/input/dai-code/run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d8b2f1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:53:17.329302Z",
     "iopub.status.busy": "2024-01-18T07:53:17.329064Z",
     "iopub.status.idle": "2024-01-18T07:53:18.270036Z",
     "shell.execute_reply": "2024-01-18T07:53:18.269095Z"
    },
    "papermill": {
     "duration": 0.962663,
     "end_time": "2024-01-18T07:53:18.272155",
     "exception": false,
     "start_time": "2024-01-18T07:53:17.309492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mconf\u001b[0m/  inference.py  preprocess.py  \u001b[01;34msrc\u001b[0m/  train.py  \u001b[01;34mwandb\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58fa55da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:53:18.312617Z",
     "iopub.status.busy": "2024-01-18T07:53:18.311948Z",
     "iopub.status.idle": "2024-01-18T07:53:18.316585Z",
     "shell.execute_reply": "2024-01-18T07:53:18.315723Z"
    },
    "papermill": {
     "duration": 0.026866,
     "end_time": "2024-01-18T07:53:18.318544",
     "exception": false,
     "start_time": "2024-01-18T07:53:18.291678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Basic Config ###\n",
    "EXP_NAME = 'exp042'\n",
    "MAX_LENGTH = 512 # inference max length\n",
    "# model_folder_name='debertav3xsmall'\n",
    "model_folder_name='huggingfacedebertav3variants/deberta-v3-large'\n",
    "# model_folder_name='huggingfacedebertav3variants/deberta-v3-base'\n",
    "\n",
    "\n",
    "### Post-process Config ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16de209b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:53:18.357747Z",
     "iopub.status.busy": "2024-01-18T07:53:18.357477Z",
     "iopub.status.idle": "2024-01-18T07:53:26.324692Z",
     "shell.execute_reply": "2024-01-18T07:53:26.323546Z"
    },
    "papermill": {
     "duration": 7.989555,
     "end_time": "2024-01-18T07:53:26.327235",
     "exception": false,
     "start_time": "2024-01-18T07:53:18.337680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      ">>> Run Preprocess\r\n",
      ">>> MAKE LM_test_preprocessed.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Preprocess\n",
    "!python -m preprocess\\\n",
    "    dir=kaggle\\\n",
    "    phase=inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "634fbae5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:53:26.368689Z",
     "iopub.status.busy": "2024-01-18T07:53:26.368335Z",
     "iopub.status.idle": "2024-01-18T07:53:50.140324Z",
     "shell.execute_reply": "2024-01-18T07:53:50.139189Z"
    },
    "papermill": {
     "duration": 23.795517,
     "end_time": "2024-01-18T07:53:50.142890",
     "exception": false,
     "start_time": "2024-01-18T07:53:26.347373",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "Run Inference\r\n",
      ">>> Load Test DataFrame & Make test_ds: COMPLETE\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\r\n",
      "  warnings.warn(\r\n",
      ">>> Define Tokenizer: COMPLETE\r\n",
      "[2024-01-18 07:53:36,640][datasets.fingerprint][WARNING] - Parameter 'function'=<function main.<locals>.tokenize_function at 0x79d862108280> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 78.57ba/s]\r\n",
      ">>> APPLY Tokenizer: COMPLETE\r\n",
      ">>> Find Best Model : /kaggle/input/dai-model/exp042/best_model/checkpoint-31698\r\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\r\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 3284.50it/s]\r\n",
      ">>> Predict: COMPLETE\r\n",
      ">>> No Post Process\r\n",
      ">>> Let's Make submission.csv\r\n",
      ">>> Inference COMPLETE\r\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "!python -m inference\\\n",
    "    dir=kaggle\\\n",
    "    exp_name=$EXP_NAME\\\n",
    "    max_length=$MAX_LENGTH\\\n",
    "    model_folder_name=$model_folder_name\\\n",
    "    post_process=False\\\n",
    "    best_model_dir=best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "72e37c5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:53:50.183878Z",
     "iopub.status.busy": "2024-01-18T07:53:50.183539Z",
     "iopub.status.idle": "2024-01-18T07:53:50.195925Z",
     "shell.execute_reply": "2024-01-18T07:53:50.195088Z"
    },
    "papermill": {
     "duration": 0.035071,
     "end_time": "2024-01-18T07:53:50.197723",
     "exception": false,
     "start_time": "2024-01-18T07:53:50.162652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   0.000033\n",
       "1  1111bbbb   0.000066\n",
       "2  2222cccc   0.000012"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/kaggle/working/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a5e076ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:53:50.238697Z",
     "iopub.status.busy": "2024-01-18T07:53:50.238421Z",
     "iopub.status.idle": "2024-01-18T07:53:50.242299Z",
     "shell.execute_reply": "2024-01-18T07:53:50.241560Z"
    },
    "papermill": {
     "duration": 0.025857,
     "end_time": "2024-01-18T07:53:50.244045",
     "exception": false,
     "start_time": "2024-01-18T07:53:50.218188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.rename('/kaggle/working/submission.csv', '/kaggle/working/submission_LM3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5ea9028",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:53:50.284174Z",
     "iopub.status.busy": "2024-01-18T07:53:50.283917Z",
     "iopub.status.idle": "2024-01-18T07:53:50.293383Z",
     "shell.execute_reply": "2024-01-18T07:53:50.292553Z"
    },
    "papermill": {
     "duration": 0.031886,
     "end_time": "2024-01-18T07:53:50.295605",
     "exception": false,
     "start_time": "2024-01-18T07:53:50.263719",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   0.000033\n",
       "1  1111bbbb   0.000066\n",
       "2  2222cccc   0.000012"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/kaggle/working/submission_LM3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0780f918",
   "metadata": {
    "papermill": {
     "duration": 0.019893,
     "end_time": "2024-01-18T07:53:50.335927",
     "exception": false,
     "start_time": "2024-01-18T07:53:50.316034",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LM4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a611a27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:53:50.376490Z",
     "iopub.status.busy": "2024-01-18T07:53:50.376216Z",
     "iopub.status.idle": "2024-01-18T07:53:50.381429Z",
     "shell.execute_reply": "2024-01-18T07:53:50.380590Z"
    },
    "papermill": {
     "duration": 0.027454,
     "end_time": "2024-01-18T07:53:50.383339",
     "exception": false,
     "start_time": "2024-01-18T07:53:50.355885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/dai-code/run\n"
     ]
    }
   ],
   "source": [
    "cd /kaggle/input/dai-code/run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57e5f4ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:53:50.423971Z",
     "iopub.status.busy": "2024-01-18T07:53:50.423694Z",
     "iopub.status.idle": "2024-01-18T07:53:51.373366Z",
     "shell.execute_reply": "2024-01-18T07:53:51.372166Z"
    },
    "papermill": {
     "duration": 0.972405,
     "end_time": "2024-01-18T07:53:51.375473",
     "exception": false,
     "start_time": "2024-01-18T07:53:50.403068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mconf\u001b[0m/  inference.py  preprocess.py  \u001b[01;34msrc\u001b[0m/  train.py  \u001b[01;34mwandb\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05768587",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:53:51.418644Z",
     "iopub.status.busy": "2024-01-18T07:53:51.417760Z",
     "iopub.status.idle": "2024-01-18T07:53:51.422445Z",
     "shell.execute_reply": "2024-01-18T07:53:51.421742Z"
    },
    "papermill": {
     "duration": 0.028461,
     "end_time": "2024-01-18T07:53:51.424324",
     "exception": false,
     "start_time": "2024-01-18T07:53:51.395863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Basic Config ###\n",
    "EXP_NAME = 'exp047'\n",
    "MAX_LENGTH = 512 # inference max length\n",
    "# model_folder_name='debertav3xsmall'\n",
    "model_folder_name='huggingfacedebertav3variants/deberta-v3-large'\n",
    "# model_folder_name='huggingfacedebertav3variants/deberta-v3-base'\n",
    "\n",
    "\n",
    "### Post-process Config ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "057bae86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:53:51.464945Z",
     "iopub.status.busy": "2024-01-18T07:53:51.464650Z",
     "iopub.status.idle": "2024-01-18T07:53:59.288552Z",
     "shell.execute_reply": "2024-01-18T07:53:59.287589Z"
    },
    "papermill": {
     "duration": 7.847102,
     "end_time": "2024-01-18T07:53:59.291180",
     "exception": false,
     "start_time": "2024-01-18T07:53:51.444078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      ">>> Run Preprocess\r\n",
      ">>> MAKE LM_test_preprocessed.csv\r\n"
     ]
    }
   ],
   "source": [
    "# Preprocess\n",
    "!python -m preprocess\\\n",
    "    dir=kaggle\\\n",
    "    phase=inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48584ee2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:53:59.334592Z",
     "iopub.status.busy": "2024-01-18T07:53:59.334284Z",
     "iopub.status.idle": "2024-01-18T07:54:24.416878Z",
     "shell.execute_reply": "2024-01-18T07:54:24.415903Z"
    },
    "papermill": {
     "duration": 25.106761,
     "end_time": "2024-01-18T07:54:24.419136",
     "exception": false,
     "start_time": "2024-01-18T07:53:59.312375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\r\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\r\n",
      "Run Inference\r\n",
      ">>> Load Test DataFrame & Make test_ds: COMPLETE\r\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\r\n",
      "  warnings.warn(\r\n",
      ">>> Define Tokenizer: COMPLETE\r\n",
      "[2024-01-18 07:54:09,630][datasets.fingerprint][WARNING] - Parameter 'function'=<function main.<locals>.tokenize_function at 0x7f4ce3d4bac0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\r\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 79.88ba/s]\r\n",
      ">>> APPLY Tokenizer: COMPLETE\r\n",
      ">>> Find Best Model : /kaggle/input/dai-model-2/exp047/best_model/checkpoint-21132\r\n",
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\r\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 2876.75it/s]\r\n",
      ">>> Predict: COMPLETE\r\n",
      ">>> No Post Process\r\n",
      ">>> Let's Make submission.csv\r\n",
      ">>> Inference COMPLETE\r\n"
     ]
    }
   ],
   "source": [
    "# Inference\n",
    "!python -m inference\\\n",
    "    dir=kaggle\\\n",
    "    exp_name=$EXP_NAME\\\n",
    "    max_length=$MAX_LENGTH\\\n",
    "    model_folder_name=$model_folder_name\\\n",
    "    post_process=False\\\n",
    "    best_model_dir=best_model\\\n",
    "    dir.model_dir=/kaggle/input/dai-model-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbf618f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:54:24.462408Z",
     "iopub.status.busy": "2024-01-18T07:54:24.462113Z",
     "iopub.status.idle": "2024-01-18T07:54:24.474807Z",
     "shell.execute_reply": "2024-01-18T07:54:24.473967Z"
    },
    "papermill": {
     "duration": 0.036456,
     "end_time": "2024-01-18T07:54:24.476810",
     "exception": false,
     "start_time": "2024-01-18T07:54:24.440354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.005166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.002057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   0.005166\n",
       "1  1111bbbb   0.002057\n",
       "2  2222cccc   0.000395"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/kaggle/working/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ffcd0d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:54:24.519362Z",
     "iopub.status.busy": "2024-01-18T07:54:24.519100Z",
     "iopub.status.idle": "2024-01-18T07:54:24.523087Z",
     "shell.execute_reply": "2024-01-18T07:54:24.522355Z"
    },
    "papermill": {
     "duration": 0.02752,
     "end_time": "2024-01-18T07:54:24.524941",
     "exception": false,
     "start_time": "2024-01-18T07:54:24.497421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.rename('/kaggle/working/submission.csv', '/kaggle/working/submission_LM4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c8a7515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:54:24.568871Z",
     "iopub.status.busy": "2024-01-18T07:54:24.568579Z",
     "iopub.status.idle": "2024-01-18T07:54:24.577676Z",
     "shell.execute_reply": "2024-01-18T07:54:24.576897Z"
    },
    "papermill": {
     "duration": 0.032482,
     "end_time": "2024-01-18T07:54:24.579550",
     "exception": false,
     "start_time": "2024-01-18T07:54:24.547068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.005166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.002057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.000395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   0.005166\n",
       "1  1111bbbb   0.002057\n",
       "2  2222cccc   0.000395"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/kaggle/working/submission_LM4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae34c64c",
   "metadata": {
    "papermill": {
     "duration": 0.02092,
     "end_time": "2024-01-18T07:54:24.621605",
     "exception": false,
     "start_time": "2024-01-18T07:54:24.600685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53b662a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:54:24.664477Z",
     "iopub.status.busy": "2024-01-18T07:54:24.664221Z",
     "iopub.status.idle": "2024-01-18T07:54:29.816873Z",
     "shell.execute_reply": "2024-01-18T07:54:29.816095Z"
    },
    "papermill": {
     "duration": 5.17681,
     "end_time": "2024-01-18T07:54:29.819290",
     "exception": false,
     "start_time": "2024-01-18T07:54:24.642480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import gc\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from spellchecker import SpellChecker\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import joblib\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from tokenizers import (\n",
    "    decoders,\n",
    "    models,\n",
    "    normalizers,\n",
    "    pre_tokenizers,\n",
    "    processors,\n",
    "    trainers,\n",
    "    Tokenizer,\n",
    ")\n",
    "from datasets import Dataset\n",
    "from transformers import PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1220469",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:54:29.867765Z",
     "iopub.status.busy": "2024-01-18T07:54:29.867132Z",
     "iopub.status.idle": "2024-01-18T07:54:29.872190Z",
     "shell.execute_reply": "2024-01-18T07:54:29.871416Z"
    },
    "papermill": {
     "duration": 0.031845,
     "end_time": "2024-01-18T07:54:29.874122",
     "exception": false,
     "start_time": "2024-01-18T07:54:29.842277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class cfg:\n",
    "    demo_mode = False\n",
    "    seed1=42\n",
    "    seed2=189\n",
    "    seed3=224\n",
    "    vocab_size=30522\n",
    "    lowercase=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6e4a3b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:54:29.918192Z",
     "iopub.status.busy": "2024-01-18T07:54:29.917922Z",
     "iopub.status.idle": "2024-01-18T07:54:33.461364Z",
     "shell.execute_reply": "2024-01-18T07:54:33.460532Z"
    },
    "papermill": {
     "duration": 3.568485,
     "end_time": "2024-01-18T07:54:33.463649",
     "exception": false,
     "start_time": "2024-01-18T07:54:29.895164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DAI_V3_train shape :  (63870, 8)\n",
      "DAI_ai_arena_V7_train shape :  (2573, 7)\n",
      "test_df shape :  (3, 3)\n",
      "After Concat DAI_V3_train shape :  (66443, 8)\n"
     ]
    }
   ],
   "source": [
    "# Train Data Load\n",
    "DAI_V3_train = pd.read_csv(\"/kaggle/input/pyspellchecker-cleaned-daigt-v3-train-dataset/pyspellchecker_cleaned_train_v3_drcat_02_typo10.csv\")\n",
    "DAI_ai_arena_V7_train = pd.read_csv(\"/kaggle/input/daigt-data-ai-arena-make/DAIGT_AI_Arena_Made_data_V7.csv\")\n",
    "print('DAI_V3_train shape : ', DAI_V3_train.shape)\n",
    "print('DAI_ai_arena_V7_train shape : ', DAI_ai_arena_V7_train.shape)\n",
    "\n",
    "# Test Data Load\n",
    "test_df = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/test_essays.csv')\n",
    "print('test_df shape : ', test_df.shape)\n",
    "\n",
    "# Train Data Concat\n",
    "DAI_V3_train = pd.concat([DAI_V3_train, DAI_ai_arena_V7_train])\n",
    "print('After Concat DAI_V3_train shape : ', DAI_V3_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1ddf0c81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:54:33.507547Z",
     "iopub.status.busy": "2024-01-18T07:54:33.507244Z",
     "iopub.status.idle": "2024-01-18T07:54:33.656848Z",
     "shell.execute_reply": "2024-01-18T07:54:33.656062Z"
    },
    "papermill": {
     "duration": 0.173665,
     "end_time": "2024-01-18T07:54:33.658902",
     "exception": false,
     "start_time": "2024-01-18T07:54:33.485237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Filter llama,ada,babbage,claude DAI_V3_train shape :  (55647, 8)\n"
     ]
    }
   ],
   "source": [
    "### Data Filtering Setting 1 : Use Only RDizzl3_seven==True in DAI_V3_train Data -> 리즐 세븐만 쓸꺼면 주석 해제\n",
    "# DAI_V3_train = DAI_V3_train[DAI_V3_train['RDizzl3_seven']==True]\n",
    "\n",
    "### Data Filtering Setting 2 : Remove 'train_essays' in DAI_V3_train Data -> train_essays 안 쓸꺼면 주석 해제\n",
    "# DAI_V3_train = DAI_V3_train[DAI_V3_train['source'] != 'train_essays']\n",
    "\n",
    "### Data Filtering Setting 3 : Remove text generated by specific Model\n",
    "DAI_V3_train = DAI_V3_train[DAI_V3_train['model'] != 'llama']\n",
    "DAI_V3_train = DAI_V3_train[DAI_V3_train['model'] != 'ada']\n",
    "DAI_V3_train = DAI_V3_train[DAI_V3_train['model'] != 'babbage']\n",
    "DAI_V3_train = DAI_V3_train[DAI_V3_train['model'] != 'claude']\n",
    "# DAI_V3_train = DAI_V3_train[DAI_V3_train['model'] != 'falcon']\n",
    "# DAI_V3_train = DAI_V3_train[DAI_V3_train['model'] != 'cohere']\n",
    "# DAI_V3_train = DAI_V3_train[DAI_V3_train['model'] != 'curie']\n",
    "print('After Filter llama,ada,babbage,claude DAI_V3_train shape : ', DAI_V3_train.shape)\n",
    "\n",
    "\n",
    "# Use 'text', 'label', 'prompt_name','source','RDizzl3_seven' columns\n",
    "# DAI_V3_train = DAI_V3_train[['text', 'label','prompt_name','source','RDizzl3_seven']]\n",
    "DAI_V3_train = DAI_V3_train[['text', 'label']]\n",
    "\n",
    "DAI_V3_train = DAI_V3_train.drop_duplicates(subset=['text'])  # 'text' 열에서 중복된 행 제거해주기\n",
    "DAI_V3_train.reset_index(drop=True, inplace=True)  # 중복된 행 제거 후, 인덱스 재설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e932f78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:54:33.703160Z",
     "iopub.status.busy": "2024-01-18T07:54:33.702884Z",
     "iopub.status.idle": "2024-01-18T07:54:33.707909Z",
     "shell.execute_reply": "2024-01-18T07:54:33.707087Z"
    },
    "papermill": {
     "duration": 0.028927,
     "end_time": "2024-01-18T07:54:33.709679",
     "exception": false,
     "start_time": "2024-01-18T07:54:33.680752",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if cfg.demo_mode: # DEMO : 100개의 행만 사용\n",
    "    demo_zero_labels = DAI_V3_train[DAI_V3_train['label'] == 0].head(50)\n",
    "    demo_one_labels = DAI_V3_train[DAI_V3_train['label'] == 1].head(50)\n",
    "    preprocessed_train_df = pd.concat([demo_zero_labels, demo_one_labels])\n",
    "    \n",
    "else:\n",
    "    preprocessed_train_df = DAI_V3_train \n",
    "    \n",
    "preprocessed_test_df = test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42d4dbe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:54:33.753692Z",
     "iopub.status.busy": "2024-01-18T07:54:33.753401Z",
     "iopub.status.idle": "2024-01-18T07:54:33.763697Z",
     "shell.execute_reply": "2024-01-18T07:54:33.762876Z"
    },
    "papermill": {
     "duration": 0.034402,
     "end_time": "2024-01-18T07:54:33.765645",
     "exception": false,
     "start_time": "2024-01-18T07:54:33.731243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "def Split_data_prompt_name(df, prompt_names):\n",
    "    train_df = df[~df['prompt_name'].isin(prompt_names)]\n",
    "    valid_df = df[df['prompt_name'].isin(prompt_names)]\n",
    "    return train_df, valid_df\n",
    "\n",
    "def train_corp_iter(dataset):\n",
    "    \"\"\"\n",
    "    A generator function for iterating over a dataset in chunks.\n",
    "    \"\"\"    \n",
    "    for i in range(0, len(dataset), 1000):\n",
    "        yield dataset[i : i + 1000][\"text\"]\n",
    "        \n",
    "def dummy(text):\n",
    "    \"\"\"\n",
    "    A dummy function to use as tokenizer for TfidfVectorizer. It returns the text as it is since we already tokenized it.\n",
    "    \"\"\"\n",
    "    return text\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text)  # -> ^는 '이외의'라는 뜻을 가짐. \\w는 모든 \"단어\"문자, \\s는 모든 공백 문자. 그 뒤의 ''는 대체할 새 문자임. 즉, 일이하는 모든 문자를 제거한다는 뜻\n",
    "                                         # 즉, 알파벳, 숫자, 공백 등을 제외한 모든 문자를 제거하게 되므로 물음표 쉼표 마침표 등의 문장부호를 제거한다.\n",
    "\n",
    "def count_typos(sentence, spell):\n",
    "    sentence_no_punct = remove_punctuation(sentence)\n",
    "    words = sentence_no_punct.split()\n",
    "    typos = spell.unknown(words)\n",
    "    return len(typos)\n",
    "\n",
    "def check_df(df, spell):\n",
    "    df['typo_num'] = df['text'].progress_apply(lambda x: count_typos(x, spell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b500e937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:54:33.809631Z",
     "iopub.status.busy": "2024-01-18T07:54:33.809383Z",
     "iopub.status.idle": "2024-01-18T07:54:33.815292Z",
     "shell.execute_reply": "2024-01-18T07:54:33.814470Z"
    },
    "papermill": {
     "duration": 0.030117,
     "end_time": "2024-01-18T07:54:33.817156",
     "exception": false,
     "start_time": "2024-01-18T07:54:33.787039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_everything(cfg.seed1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fdf7cb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:54:33.860903Z",
     "iopub.status.busy": "2024-01-18T07:54:33.860616Z",
     "iopub.status.idle": "2024-01-18T07:54:33.864379Z",
     "shell.execute_reply": "2024-01-18T07:54:33.863592Z"
    },
    "papermill": {
     "duration": 0.027508,
     "end_time": "2024-01-18T07:54:33.866269",
     "exception": false,
     "start_time": "2024-01-18T07:54:33.838761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = preprocessed_train_df\n",
    "test_df = preprocessed_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3afba187",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T07:54:33.909772Z",
     "iopub.status.busy": "2024-01-18T07:54:33.909505Z",
     "iopub.status.idle": "2024-01-18T08:02:54.300468Z",
     "shell.execute_reply": "2024-01-18T08:02:54.299535Z"
    },
    "papermill": {
     "duration": 500.415741,
     "end_time": "2024-01-18T08:02:54.303124",
     "exception": false,
     "start_time": "2024-01-18T07:54:33.887383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 3416.48it/s]\n",
      "100%|██████████| 55636/55636 [02:45<00:00, 336.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# 토크나이저 정의 : tokenizers의 models에서 BPE를 선택한다.\n",
    "raw_tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))  # unkown token을 [UNK]로 설정\n",
    "\n",
    "# 토크나이저 정규화 & 프리 토크나이저 Level 설정\n",
    "# NFC 정규화를 기본으로 하며, cfg.lowercase가 True라면 소문자 변환을 추가한다.\n",
    "raw_tokenizer.normalizer = normalizers.Sequence([normalizers.NFC()] + [normalizers.Lowercase()] if cfg.lowercase else [])  \n",
    "raw_tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
    "\n",
    "# 스페셜 토큰 추가, trainer 생성\n",
    "special_tokens = [\"[UNK]\", \"[PAD]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
    "trainer = trainers.BpeTrainer(vocab_size=cfg.vocab_size, special_tokens=special_tokens)\n",
    "\n",
    "# Dataset 정의\n",
    "dataset = Dataset.from_pandas(test_df[['text']])\n",
    "\n",
    "\n",
    "# 토크나이저 Train\n",
    "# 토크나이저를 train한다라는 것? → 어휘 사전(vocabulary)을 구축하는 것\n",
    "raw_tokenizer.train_from_iterator(train_corp_iter(dataset), trainer=trainer)\n",
    "\n",
    "\n",
    "# 훈련된 토크나이저를 기반으로 PreTrainedTokenizerFast 생성\n",
    "# 참고 링크 : https://wikidocs.net/166828    \n",
    "# 커스텀 Tokenizer (raw_tokenizer)를 사용하려면 PreTrainedTokenizerFast로 래핑해야한다고 한다.\n",
    "# 이 경우 모든 스페셜 토큰을 수동으로 직접 설정해야 한다.\n",
    "tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=raw_tokenizer,\n",
    "    unk_token=\"[UNK]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    cls_token=\"[CLS]\",\n",
    "    sep_token=\"[SEP]\",\n",
    "    mask_token=\"[MASK]\",\n",
    ")\n",
    "\n",
    "# Tokenize test set with new tokenizer      \n",
    "tokenized_texts_test = []  # -> 토큰화된 결과를 리스트에 저장\n",
    "for text in tqdm(test_df['text'].tolist()):\n",
    "    tokenized_texts_test.append(tokenizer.tokenize(text))\n",
    "\n",
    "# Tokenize train set\n",
    "tokenized_texts_train = []  # -> 토큰화된 결과를 리스트에 저장\n",
    "for text in tqdm(train_df['text'].tolist()):\n",
    "    tokenized_texts_train.append(tokenizer.tokenize(text))\n",
    "\n",
    "\n",
    "# TF-IDF Vectorizer 적용하여 text data를 TF-IDF 벡터로 변환한다.\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3, 5), lowercase=False, sublinear_tf=True, analyzer = 'word',\n",
    "    tokenizer = dummy,  # dummy 함수를 쓰는 이유 : 이미 Dataset이 커스텀 토크나이저에 의해서 토큰화된 상태이기 때문에, 입력된 text를 그대로 반환하는 dummy 함수 이용\n",
    "    preprocessor = dummy,\n",
    "    token_pattern = None, strip_accents='unicode'\n",
    "                            )\n",
    "\n",
    "vectorizer.fit(tokenized_texts_test)  # 토큰화된 Test text에 대해서 TFidfVectorizer를 fit 시킨다 -> vocab이 생성된다.\n",
    "\n",
    "\n",
    "# Getting vocab\n",
    "vocab = vectorizer.vocabulary_  # 이 vocab은 Test data에 등장하는 토큰들로 만들어진 것\n",
    "\n",
    "\n",
    "# Here we fit our vectorizer on train set but this time we use vocabulary from test fit.\n",
    "# Test data에 대해서 생성된 vocab을 이용해서 또 다른 TFidfVectorizer를 생성한다.\n",
    "vectorizer = TfidfVectorizer(ngram_range=(3, 5), lowercase=False, sublinear_tf=True, vocabulary=vocab,\n",
    "                            analyzer = 'word',\n",
    "                            tokenizer = dummy,\n",
    "                            preprocessor = dummy,\n",
    "                            token_pattern = None, strip_accents='unicode'\n",
    "                            )\n",
    "\n",
    "\n",
    "# 바로 위에서 만든 vectorizer를 train dataset에 fit_transform를 하며, 같은 vectorizer로 test dataset에 대해서는 transform을 수행한다.\n",
    "# fit_transform : 데이터에 대해서 fit을 수행하고, 데이터를 TF-IDF 벡터로 변환하는 작업만 수행\n",
    "# transform : 데이터를 TF-IDF 벡터로 변환하는 작업만 수행\n",
    "tf_train = vectorizer.fit_transform(tokenized_texts_train)\n",
    "tf_test = vectorizer.transform(tokenized_texts_test)\n",
    "\n",
    "y_train = train_df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eafdaf2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T08:02:54.589563Z",
     "iopub.status.busy": "2024-01-18T08:02:54.588727Z",
     "iopub.status.idle": "2024-01-18T08:03:02.755395Z",
     "shell.execute_reply": "2024-01-18T08:03:02.754371Z"
    },
    "papermill": {
     "duration": 8.310463,
     "end_time": "2024-01-18T08:03:02.757598",
     "exception": false,
     "start_time": "2024-01-18T08:02:54.447135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "/opt/conda/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/lib/python3.10/site-packages/dask/dataframe/_pyarrow_compat.py:23: UserWarning: You are using pyarrow version 11.0.0 which is known to be insecure. See https://www.cve.org/CVERecord?id=CVE-2023-47248 for further details. Please upgrade to pyarrow>=14.0.1 or install pyarrow-hotfix to patch your current version.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
      "/opt/conda/lib/python3.10/site-packages/lightgbm/engine.py:177: UserWarning: Found `n_iter` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_model = MultinomialNB(alpha=0.02)\n",
    "\n",
    "sgd_model_1 = SGDClassifier(max_iter=8000,\n",
    "                            tol=1e-4,\n",
    "                            loss=\"modified_huber\",\n",
    "                            random_state=cfg.seed1, \n",
    "                            )\n",
    "sgd_model_2 = SGDClassifier(max_iter=8000,\n",
    "                            tol=1e-4,\n",
    "                            loss=\"modified_huber\",\n",
    "                            random_state=cfg.seed2, \n",
    "                            )\n",
    "sgd_model_3 = SGDClassifier(max_iter=8000,\n",
    "                            tol=1e-4,\n",
    "                            loss=\"modified_huber\",\n",
    "                            random_state=cfg.seed3, \n",
    "                            )\n",
    "\n",
    "p1={'n_iter': 2500,\n",
    "    'verbose': -1,\n",
    "    'objective': 'cross_entropy',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.00581909898961407, \n",
    "    'colsample_bytree': 0.78,\n",
    "    'colsample_bynode': 0.8, \n",
    "    'lambda_l1': 4.562963348932286, \n",
    "    'lambda_l2': 2.97485, \n",
    "    'min_data_in_leaf': 115, \n",
    "    'max_depth': 23, \n",
    "    'max_bin': 898}\n",
    "\n",
    "p2={'n_iter': 2500,\n",
    "    'verbose': -1,\n",
    "    'objective': 'cross_entropy',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.00581909898961407, \n",
    "    'colsample_bytree': 0.78,\n",
    "    'colsample_bynode': 0.8, \n",
    "    'lambda_l1': 4.562963348932286, \n",
    "    'lambda_l2': 2.97485, \n",
    "    'min_data_in_leaf': 115, \n",
    "    'max_depth': 23, \n",
    "    'max_bin': 898}\n",
    "\n",
    "p3={'n_iter': 2500,\n",
    "    'verbose': -1,\n",
    "    'objective': 'cross_entropy',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.00581909898961407, \n",
    "    'colsample_bytree': 0.78,\n",
    "    'colsample_bynode': 0.8, \n",
    "    'lambda_l1': 4.562963348932286, \n",
    "    'lambda_l2': 2.97485, \n",
    "    'min_data_in_leaf': 115, \n",
    "    'max_depth': 23, \n",
    "    'max_bin': 898}\n",
    "\n",
    "\n",
    "lgb_model_1=LGBMClassifier(**p1,\n",
    "                           random_state=cfg.seed1, \n",
    "                          )\n",
    "lgb_model_2=LGBMClassifier(**p2,\n",
    "                           random_state=cfg.seed2, \n",
    "                          )\n",
    "lgb_model_3=LGBMClassifier(**p3,\n",
    "                           random_state=cfg.seed3,\n",
    "                          )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "weights = [0.1, 0.05, 0.05, # sgd\n",
    "           0.4,  # nb\n",
    "           0.15, 0.15, 0.1 # lgb\n",
    "          ] \n",
    "\n",
    "ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('sgd_1', sgd_model_1),\n",
    "        ('sgd_2', sgd_model_2),\n",
    "        ('sgd_3', sgd_model_3),\n",
    "        ('nb', bayes_model),\n",
    "        ('lgb_1', lgb_model_1),\n",
    "        ('lgb_2', lgb_model_2),\n",
    "        ('lgb_3', lgb_model_3),\n",
    "    ],\n",
    "    weights=weights,\n",
    "    voting='soft', \n",
    "    n_jobs=-1\n",
    ")\n",
    "ensemble.fit(tf_train, y_train)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "95150f64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T08:03:03.062113Z",
     "iopub.status.busy": "2024-01-18T08:03:03.061649Z",
     "iopub.status.idle": "2024-01-18T08:03:03.071059Z",
     "shell.execute_reply": "2024-01-18T08:03:03.070011Z"
    },
    "papermill": {
     "duration": 0.156124,
     "end_time": "2024-01-18T08:03:03.073332",
     "exception": false,
     "start_time": "2024-01-18T08:03:02.917208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_preds = ensemble.predict_proba(tf_test)[:,1]\n",
    "test_df['generated'] = final_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69e4661b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T08:03:03.375347Z",
     "iopub.status.busy": "2024-01-18T08:03:03.374361Z",
     "iopub.status.idle": "2024-01-18T08:03:03.378989Z",
     "shell.execute_reply": "2024-01-18T08:03:03.378097Z"
    },
    "papermill": {
     "duration": 0.157439,
     "end_time": "2024-01-18T08:03:03.380989",
     "exception": false,
     "start_time": "2024-01-18T08:03:03.223550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "####################\n",
    "#   Post-Process   #\n",
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b6cce4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T08:03:03.667380Z",
     "iopub.status.busy": "2024-01-18T08:03:03.667045Z",
     "iopub.status.idle": "2024-01-18T08:03:03.675892Z",
     "shell.execute_reply": "2024-01-18T08:03:03.674881Z"
    },
    "papermill": {
     "duration": 0.154618,
     "end_time": "2024-01-18T08:03:03.677774",
     "exception": false,
     "start_time": "2024-01-18T08:03:03.523156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = test_df[['id', 'generated']]\n",
    "sub.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90e2f5ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T08:03:03.981321Z",
     "iopub.status.busy": "2024-01-18T08:03:03.980960Z",
     "iopub.status.idle": "2024-01-18T08:03:03.993015Z",
     "shell.execute_reply": "2024-01-18T08:03:03.992112Z"
    },
    "papermill": {
     "duration": 0.16327,
     "end_time": "2024-01-18T08:03:03.995027",
     "exception": false,
     "start_time": "2024-01-18T08:03:03.831757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.507236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.507236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.507236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   0.507236\n",
       "1  1111bbbb   0.507236\n",
       "2  2222cccc   0.507236"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/kaggle/working/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d0ee17d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T08:03:04.288552Z",
     "iopub.status.busy": "2024-01-18T08:03:04.288224Z",
     "iopub.status.idle": "2024-01-18T08:03:04.292605Z",
     "shell.execute_reply": "2024-01-18T08:03:04.291826Z"
    },
    "papermill": {
     "duration": 0.157234,
     "end_time": "2024-01-18T08:03:04.294556",
     "exception": false,
     "start_time": "2024-01-18T08:03:04.137322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.rename('/kaggle/working/submission.csv', '/kaggle/working/submission_TV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2bccdc8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T08:03:04.579395Z",
     "iopub.status.busy": "2024-01-18T08:03:04.579100Z",
     "iopub.status.idle": "2024-01-18T08:03:04.589671Z",
     "shell.execute_reply": "2024-01-18T08:03:04.588868Z"
    },
    "papermill": {
     "duration": 0.151883,
     "end_time": "2024-01-18T08:03:04.591547",
     "exception": false,
     "start_time": "2024-01-18T08:03:04.439664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.507236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.507236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.507236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   0.507236\n",
       "1  1111bbbb   0.507236\n",
       "2  2222cccc   0.507236"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/kaggle/working/submission_TV.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a72ebd0",
   "metadata": {
    "papermill": {
     "duration": 0.14283,
     "end_time": "2024-01-18T08:03:04.880978",
     "exception": false,
     "start_time": "2024-01-18T08:03:04.738148",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Total LM - TV Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c812dde1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T08:03:05.209594Z",
     "iopub.status.busy": "2024-01-18T08:03:05.208918Z",
     "iopub.status.idle": "2024-01-18T08:03:05.226140Z",
     "shell.execute_reply": "2024-01-18T08:03:05.225178Z"
    },
    "papermill": {
     "duration": 0.206422,
     "end_time": "2024-01-18T08:03:05.228170",
     "exception": false,
     "start_time": "2024-01-18T08:03:05.021748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub_LM1 = pd.read_csv('/kaggle/working/submission_LM1.csv')\n",
    "sub_LM2 = pd.read_csv('/kaggle/working/submission_LM2.csv')\n",
    "sub_LM3 = pd.read_csv('/kaggle/working/submission_LM3.csv')\n",
    "sub_LM4 = pd.read_csv('/kaggle/working/submission_LM4.csv')\n",
    "\n",
    "\n",
    "sub_TV = pd.read_csv('/kaggle/working/submission_TV.csv')\n",
    "\n",
    "ensemble = 0.1*sub_LM1['generated'] + 0.1*sub_LM2['generated'] + 0.05*sub_LM3['generated'] + 0.1*sub_LM4['generated'] + 0.65*sub_TV['generated']\n",
    "\n",
    "ensem_result = pd.DataFrame({\n",
    "    'id': sub_LM1['id'],\n",
    "    'generated': ensemble\n",
    "})\n",
    "\n",
    "ensem_result.to_csv('/kaggle/working/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a93079f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-18T08:03:05.517819Z",
     "iopub.status.busy": "2024-01-18T08:03:05.517199Z",
     "iopub.status.idle": "2024-01-18T08:03:05.528194Z",
     "shell.execute_reply": "2024-01-18T08:03:05.527271Z"
    },
    "papermill": {
     "duration": 0.155619,
     "end_time": "2024-01-18T08:03:05.530216",
     "exception": false,
     "start_time": "2024-01-18T08:03:05.374597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000aaaa</td>\n",
       "      <td>0.330263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111bbbb</td>\n",
       "      <td>0.334301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2222cccc</td>\n",
       "      <td>0.329766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  generated\n",
       "0  0000aaaa   0.330263\n",
       "1  1111bbbb   0.334301\n",
       "2  2222cccc   0.329766"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('/kaggle/working/submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebab0737",
   "metadata": {
    "papermill": {
     "duration": 0.139522,
     "end_time": "2024-01-18T08:03:05.810231",
     "exception": false,
     "start_time": "2024-01-18T08:03:05.670709",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 7516023,
     "sourceId": 61542,
     "sourceType": "competition"
    },
    {
     "datasetId": 1825054,
     "sourceId": 2977194,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2663421,
     "sourceId": 4620664,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3596984,
     "sourceId": 6258399,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3789196,
     "sourceId": 6557764,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4005256,
     "sourceId": 6977472,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4210720,
     "sourceId": 7294503,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4241497,
     "sourceId": 7378583,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4200418,
     "sourceId": 7391276,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4246935,
     "sourceId": 7416301,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4200397,
     "sourceId": 7416375,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4314449,
     "sourceId": 7422268,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4319426,
     "sourceId": 7423766,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4320820,
     "sourceId": 7425884,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 144358840,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 725.652859,
   "end_time": "2024-01-18T08:03:09.073108",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-18T07:51:03.420249",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
